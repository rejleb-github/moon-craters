{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Usage: crater_make_dataset.py\n",
    "\n",
    "Functions for combining LRO LOLA Elevation Model heightmap (https://astrogeology.usgs.gov/search/details/Moon/LRO/LOLA/Lunar_LRO_LOLA_Global_LDEM_118m_Mar2014/cub) and Goran Salamuniccar's database (https://astrogeology.usgs.gov/search/map/Moon/Research/Craters/GoranSalamuniccar_MoonCraters).  \n",
    "\n",
    "The LRO image is a \"simple cylindrical\" projection, which is synonymous with Equidistant Cylindrical or Plate Carree (http://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/equidistant-cylindrical.htm).\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageChops\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import image_slicer as imsl\n",
    "import glob\n",
    "\n",
    "def ReadCraterCSV(filename=\"./alandataset.csv\"):\n",
    "    \"\"\"Reads crater file CSV.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        csv file of craters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    craters : pandas.DataFrame\n",
    "        Craters data frame.\n",
    "    \"\"\"\n",
    "    # Read in crater names\n",
    "#    craters_names = [\"ID\", \"Long\", \"Lat\", \"Radius (deg)\", \n",
    "#                        \"Diameter (km)\", \"D_range\", \"p\", \"Name\"]\n",
    "#    craters_types = [str, float, float, float, float, float, int, str]\n",
    "#    craters = pd.read_csv(open(filename, 'r'), sep=',', \n",
    "#        usecols=list(range(8)), header=0, engine=\"c\", encoding = \"ISO-8859-1\",\n",
    "#        names=craters_names, dtype=dict(zip(craters_names, craters_types)))\n",
    "\n",
    "    # Truncate cyrillic characters\n",
    "#    craters[\"Name\"] = craters[\"Name\"].str.split(\":\").str.get(0)\n",
    "#    craters = pd.read_csv('./LU78287GT.csv', header=0)\n",
    "\n",
    "    craters = pd.read_csv('./alanalldata.csv', header=0)\n",
    "\n",
    "\n",
    "\n",
    "    craters.sort_values(by='Lat', inplace=True)\n",
    "\n",
    "    return craters\n",
    "\n",
    "\n",
    "# Equidistant cylindrical projections have latitude and longitude\n",
    "# in constant vertical and horizontal increments, respectively.\n",
    "\n",
    "def coord2pix(longitude, latitude, imgdim, origin=\"upper\"):\n",
    "    \"\"\"Converts Plate Carree lat/long to image pixel locations.\n",
    "    Assumes central meridian is at 0 (so long in [-180, 180) ).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    longitude : float or ndarray\n",
    "        Longitude\n",
    "    latitude : float or ndarray\n",
    "        Latitude\n",
    "    imgdim : list, tuple or ndarray\n",
    "        Length and height of image, in pixels\n",
    "    origin : \"upper\" or \"lower\"\n",
    "        Based on imshow convention for displaying image y-axis.\n",
    "        \"upper\" means that [0,0] is upper-left corner of image;\n",
    "        \"lower\" means it is bottom-left.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x : ndarray\n",
    "        x positions\n",
    "    y : ndarray\n",
    "        y positions\n",
    "    \"\"\"\n",
    "\n",
    "    x = imgdim[0]*(longitude/360. + 0.5)\n",
    "\n",
    "    if origin == \"lower\":\n",
    "        y = imgdim[1]*(0.5 + latitude/180.)\n",
    "    else:\n",
    "        y = imgdim[1]*(0.5 - latitude/180.)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def pix2coord(x, y, imgdim, origin=\"upper\"):\n",
    "    \"\"\"Converts image pixel locations to Plate Carree lat/long.\n",
    "    Assumes central meridian is at 0 (so long in [-180, 180) ).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float or ndarray\n",
    "        x positions\n",
    "    y : float or ndarray\n",
    "        y positions\n",
    "    imgdim : list, tuple or ndarray\n",
    "        Length and height of image, in pixels\n",
    "    origin : \"upper\" or \"lower\"\n",
    "        Based on imshow convention for displaying image y-axis.\n",
    "        \"upper\" means that [0,0] is upper-left corner of image;\n",
    "        \"lower\" means it is bottom-left.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    latitude : ndarray\n",
    "        Latitude\n",
    "    longitude : ndarray\n",
    "        Longitude\n",
    "    \"\"\"\n",
    "    longitude = 180.*(2.*x/imgdim[0] - 1.)\n",
    "    latitude = 90.*(1. - 2.*y/imgdim[1])\n",
    "\n",
    "    if origin == \"lower\":\n",
    "        latitude *= -1\n",
    "\n",
    "    return longitude, latitude\n",
    "\n",
    "\n",
    "############# Plotting functions #############\n",
    "\n",
    "\n",
    "def PlotMoonPic(img, craterlist, savefig=False, borderless=False,\n",
    "                    length=10.):\n",
    "    \"\"\"Matplotlib plot (without using Cartopy) of Moon image\n",
    "    and crater locations.  Useful for comparing Plate Carree\n",
    "    maps generated by PlotMoonMap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : str or ndarray\n",
    "        Name of file or image file in ndarray form.\n",
    "    craters : dict\n",
    "        Dictionary that includes x and y coordinates of crater\n",
    "        centroids.\n",
    "    savefig : str or bool\n",
    "        If true, use as filename.  If False, do not save figure.\n",
    "    borderless : bool\n",
    "        Removes whitespace from image\n",
    "    length : float\n",
    "        If borderless=True, sets length of figure\n",
    "    \"\"\"\n",
    "\n",
    "    if type(img) == str:\n",
    "        img = plt.imread(img)\n",
    "\n",
    "    if borderless:\n",
    "        fig = plt.figure(figsize=[length, length*img.shape[0]/img.shape[1]])\n",
    "        ax = fig.add_axes([0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "    else:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.imshow(img, origin='upper')\n",
    "    if craterlist[\"x\"].size > 0:\n",
    "        ax.scatter(craterlist[\"x\"], craterlist[\"y\"])\n",
    "    quiet = ax.axis([0, img.shape[1], img.shape[0], 0])\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(savefig, dpi = 200, edgecolor = 'w')\n",
    "\n",
    "\n",
    "# Note to self: for tutorials on cartopy, see:\n",
    "# http://scitools.org.uk/cartopy/docs/v0.13/matplotlib/advanced_plotting.html\n",
    "# http://scitools.org.uk/cartopy/docs/latest/examples/geostationary.html\n",
    "# http://scitools.org.uk/iris/docs/v1.9.1/examples/General/projections_and_annotations.html\n",
    "# https://uoftcoders.github.io/studyGroup/lessons/python/cartography/lesson/\n",
    "\n",
    "def PlotMoonMap(img=\"./maindata.png\", craters=False, mindiam=0., \n",
    "                        projection=ccrs.Mollweide(central_longitude=0), savefig=False):\n",
    "    \"\"\"Cartopy plot of largest named craters (see code comments for references).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : str or ndarray\n",
    "        Name of file or image file in ndarray form.\n",
    "    craters : bool or pandas.DataFrame\n",
    "        LU78287GT craters.  If false, loads from file.\n",
    "    mindiam : float\n",
    "        Minimum crater diameter for inclusion in plot\n",
    "    projection : cartopy.crs projection\n",
    "        Map projection\n",
    "    savefig : str or bool\n",
    "        If true, use as filename.  If False, do not save figure.\n",
    "    \"\"\"\n",
    "\n",
    "    if type(img) == str:\n",
    "        img = plt.imread(img)\n",
    "\n",
    "    # Load craters table\n",
    "    if not type(craters) == pd.core.frame.DataFrame:\n",
    "        craters = ReadCraterCSV()\n",
    "    big_name_craters = craters[(craters[\"Name\"].notnull()) & \n",
    "                                (craters[\"Diameter (km)\"] > mindiam)]\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # Feeding the projection keyword a ccrs method turns ax into a \n",
    "    # cartopy.mpl.geoaxes.GeoAxes object, which supports coordinate \n",
    "    # system transforms.\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=projection)\n",
    "\n",
    "    # As noted in the Iris projections and annotations example, transform \n",
    "    # specifies a non-display coordinate system for the data points.\n",
    "    ax.imshow(img, transform=ccrs.PlateCarree(central_longitude=0), \n",
    "                extent=[-180, 180, -90, 90], origin='upper')\n",
    "\n",
    "    ax.scatter(big_name_craters[\"Long\"], big_name_craters[\"Lat\"], \n",
    "                    transform=ccrs.PlateCarree(central_longitude=0))\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(savefig, dpi = 200, edgecolor = 'w')\n",
    "\n",
    "\n",
    "def PlotComparison():\n",
    "    \"\"\"Script to compare home-brewed and cartopy plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Note to self: use scipy.ndimage.imread or \n",
    "    # Image.open('image.png').convert('LA') if you need \n",
    "    # to flatten to greyscale\n",
    "\n",
    "    img = plt.imread(\"./moonmap_small.png\")\n",
    "    craters = ReadCraterCSV()\n",
    "    mindiam = 0.\n",
    "\n",
    "    crater_sub = craters.loc[(craters[\"Name\"].notnull()) & \n",
    "                                (craters[\"Diameter (km)\"] > mindiam)]\n",
    "\n",
    "    cx, cy = coord2pix(crater_sub[\"Long\"].as_matrix(), \n",
    "                        crater_sub[\"Lat\"].as_matrix(), \n",
    "                        [img.shape[1], img.shape[0]])\n",
    "\n",
    "    PlotMoonPic(img, {\"x\": cx, \"y\": cy}, savefig=\"./test_moonpic.png\")\n",
    "\n",
    "    PlotMoonMap(img=img, craters=craters, mindiam=mindiam, \n",
    "                    projection=ccrs.PlateCarree(central_longitude=0), \n",
    "                    savefig=\"./test_moonmap.png\")\n",
    "\n",
    "\n",
    "def TrimImageWhitespace(img, outimg):\n",
    "    \"\"\"Trims whitespace from image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : str\n",
    "        Name of file.\n",
    "    outimg : str\n",
    "        Filename of output.\n",
    "    \"\"\"\n",
    "    im = Image.open(img)\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return im.crop(bbox)\n",
    "    im.save(outimg, format=\"png\")\n",
    "\n",
    "\n",
    "######################################################\n",
    "\n",
    "\n",
    "############# Input data maker functions #############\n",
    "\n",
    "def AddXY(craters, imgdim, origin=\"upper\"):\n",
    "    \"\"\"Adds x and y pixel locations to craters dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    craters : pandas.DataFrame\n",
    "        LU78287GT craters\n",
    "    imgdim : list, tuple or ndarray\n",
    "        Length and height of image, in pixels\n",
    "    origin : \"upper\" or \"lower\"\n",
    "        Based on imshow convention for displaying image y-axis.\n",
    "        \"upper\" means that [0,0] is upper-left corner of image;\n",
    "        \"lower\" means it is bottom-left.\n",
    "    \"\"\"\n",
    "    x, y = coord2pix(craters[\"Long\"].as_matrix(), craters[\"Lat\"].as_matrix(), \n",
    "                        imgdim, origin=origin)\n",
    "    craters[\"x\"] = x\n",
    "    craters[\"y\"] = y\n",
    "\n",
    "\n",
    "def CreateDataSet(img, craters, splitnum, outprefix=\"out\"):\n",
    "    \"\"\"Creates set of images and accompanying csvs of crater data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : str\n",
    "        Name of file.\n",
    "    craters : bool or pandas.DataFrame\n",
    "        LU78287GT craters.  If false, loads from file.        \n",
    "    splitnum : int\n",
    "        Number of subfiles to split image into.\n",
    "    outprefix : str\n",
    "        Output files' prefix.\n",
    "    \"\"\"\n",
    "\n",
    "    tiles = imsl.slice(img, splitnum, save=False)\n",
    "    imgshape = imsl.get_combined_size(tiles)\n",
    "\n",
    "    # Origin is upper for image_slicer, and shapes\n",
    "    # are x-axis (\"columns\") first, rather than\n",
    "    # rows as in plt.imread\n",
    "    if not type(craters) == pd.core.frame.DataFrame:\n",
    "        craters = ReadCraterCSV()\n",
    "    AddXY(craters, [imgshape[0], imgshape[1]], origin=\"upper\")\n",
    "\n",
    "    for tile in tiles:\n",
    "        # Get x, y limits of image\n",
    "        ctr_xlim = (craters[\"x\"] > tile.coords[0]) & \\\n",
    "                    (craters[\"x\"] < tile.coords[0] + tile.image.size[0])\n",
    "        ctr_ylim = (craters[\"y\"] > tile.coords[1]) & \\\n",
    "                    (craters[\"y\"] < tile.coords[1] + tile.image.size[1])\n",
    "\n",
    "        # Get subset of craters within these limits\n",
    "        curr_craters = craters.loc[ctr_xlim & ctr_ylim, ['Long', 'Lat', \n",
    "                                    'Radius (deg)', 'Diameter (km)',\n",
    "                                    'x', 'y', 'Name']].copy()\n",
    "        curr_craters.loc[:,\"x\"] -= tile.coords[0]\n",
    "        curr_craters.loc[:,\"y\"] -= tile.coords[1]\n",
    "\n",
    "        # Print image and crater subset out\n",
    "        outname = tile.generate_filename(prefix=outprefix,\n",
    "                          format='png', path=True)\n",
    "        tile.save(outname, format=\"png\")\n",
    "        curr_craters.to_csv(outname.split(\".png\")[0] + \".csv\", index=False)\n",
    "\n",
    "\n",
    "def CheckDataSet(imagelist):\n",
    "    \"\"\"Overplots csv crater locations onto images made\n",
    "    by CreateDataSet.\n",
    "    \"\"\"\n",
    "\n",
    "    for imagename in imagelist:\n",
    "        craters = pd.read_csv(open(imagename.split(\".png\")[0] + \".csv\", 'r'), \n",
    "            sep=',', header=0, engine=\"c\", encoding = \"ISO-8859-1\")\n",
    "        img = plt.imread(imagename)\n",
    "        PlotMoonPic(img, craters, savefig=imagename.split(\".png\")[0] + \"_check.png\", \n",
    "                        borderless=True, length=img.shape[1]/200.)\n",
    "\n",
    "\n",
    "######################################################\n",
    "\n",
    "\n",
    "############# Main/test functions #############\n",
    "\n",
    "\n",
    "def BigCraters():\n",
    "    craters = ReadCraterCSV()\n",
    "    big_name_craters = craters[(craters[\"Name\"].notnull()) & \\\n",
    "                                    (craters[\"Diameter (km)\"] > 0.)].copy()\n",
    "    CreateDataSet(\"./maindata.png\", big_name_craters, 6, outprefix=\"out/out\")\n",
    "\n",
    "    imagelist = sorted(glob.glob(\"out/out*.png\"))\n",
    "    CheckDataSet(imagelist)\n",
    "\n",
    "\n",
    "# Can check against:\n",
    "# https://tools.wmflabs.org/geohack/geohack.php?pagename=Tycho_%28crater%29&params=43.47_S_16.30_W_globe:moon&title=Tycho+S\n",
    "\n",
    "def ProminentCrater(cratername=\"Copernicus r\"):\n",
    "    \"\"\"Checks if one prominent crater is in the right spot\n",
    "    in split images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cratername : str\n",
    "        Crater name.  Try \"Copernicus r\" or \"Tycho r\".\n",
    "    \"\"\"\n",
    "\n",
    "    craters = ReadCraterCSV()\n",
    "    tycho = craters[craters['Name'].str.contains(cratername).fillna(False)].copy()\n",
    "    CreateDataSet(\"./maindata.png\", tycho, 4, outprefix=\"out/octr\")\n",
    "\n",
    "    imagelist = sorted(glob.glob(\"out/octr*.png\"))\n",
    "    CheckDataSet(imagelist)\n",
    "\n",
    "\n",
    "    # execute only if run as a script\n",
    "    #BigCraters()\n",
    "craters = ReadCraterCSV(filename=\"./alanalldata.csv\")\n",
    "CreateDataSet(\"maindata.png\", craters, 1000, outprefix=\"output_dir/out\")\n",
    "#    BigCraters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#path =r'./output_dir' # use your path\n",
    "#allFiles = glob.glob(path + \"/*.csv\")\n",
    "#allFilesimg = glob.glob(path + \"/*.png\")\n",
    "\n",
    "#target = []\n",
    "#for file_ in allFiles:\n",
    "#    df = pd.read_csv(file_,header=0) \n",
    "#    target.append('%s,%i' % ((file_),len(df.index)))\n",
    "#target=pd.DataFrame(target)  \n",
    "#target = pd.DataFrame(target[0].str.split(',').tolist())\n",
    "#target.columns = ['file', 'craters']\n",
    "#target['file'] = target['file'].map(lambda x: str(x)[13:])\n",
    "#target['file'] = target['file'].map(lambda x: str(x)[:9])\n",
    "#target['file'] = target['file'].map(lambda x: str(x)+'.png')\n",
    "#y_train = target\n",
    "\n",
    "#y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mad/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 1.2.0\n",
      "Read train images\n",
      "Load folder output_dir (Index: 0)\n",
      "Convert to numpy...\n",
      "Convert to float...\n",
      "('Train shape:', (1024, 3, 224, 224))\n",
      "(1024, 'train samples')\n",
      "Loading ResNet50 Weights ...\n",
      "Adding Average Pooling Layer and Softmax Output Layer ...\n",
      "Start KFold number 1 from 2\n",
      "('Split train: ', 512, 512)\n",
      "('Split valid: ', 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# For GPU run with:\n",
    "#THEANO_FLAGS='floatX=float32,device=gpu,lib.cnmem=.50,allow_gc=False, profile=True' CUDA_LAUNCH_BLOCKING=1 time  python test.py \n",
    "\n",
    "################################# Import Stuffs #################################\n",
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras import __version__ as keras_version\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "#################################\n",
    "\n",
    "learning_rate = 0.0001\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "#nbr_train_samples = 3019\n",
    "#nbr_validation_samples = 758\n",
    "#nbr_epochs = 25\n",
    "#batch_size = 32\n",
    "#################################\n",
    "\n",
    "\n",
    "################################# READ FILES, DONT CHANGE #################################\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    #resized = cv2.resize(img, (32, 32))#, cv2.INTER_LINEAR)\n",
    "    resized = cv2.resize(img, (img_width, img_height))#, cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "    folders = ['output_dir']\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('./', fld, '*.png')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = get_im_cv2(fl)\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(fl)\n",
    "            y_train.append(y_trainn2(fl))\n",
    "\n",
    "\n",
    "\n",
    "#    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id\n",
    "def read_and_normalize_train_data():\n",
    "    train_data, train_target, train_id = load_train()\n",
    "\n",
    "    print('Convert to numpy...')\n",
    "    train_data = np.array(train_data, dtype=np.uint8)\n",
    "    train_target = np.array(train_target, dtype=np.uint8)\n",
    "    #print('Reshape...') # No reshape to get tensorflow ordering\n",
    "    train_data = train_data.transpose((0, 3, 1, 2))\n",
    "\n",
    "    print('Convert to float...')\n",
    "    train_data = train_data.astype('float32')\n",
    "    train_data = train_data / 255\n",
    "    #train_target = np_utils.to_categorical(train_target, 8)\n",
    "\n",
    "    print('Train shape:', train_data.shape)\n",
    "    print(train_data.shape[0], 'train samples')\n",
    "    return train_data, train_target, train_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def y_trainn2(file_):\n",
    "    target = []    \n",
    "    file2_=file_[:22]\n",
    "    file2_=str(file2_)+'.csv'\n",
    "    df = pd.read_csv(file2_ , header=0) \n",
    "    target.append(len(df.index))\n",
    "    return target\n",
    "###################################################################################################\n",
    "\n",
    "################################################# Convnet Model  #############################################\n",
    "def create_model_resnet():\n",
    "    print('Loading ResNet50 Weights ...')\n",
    "    ResNet50_notop = ResNet50(include_top=False, weights='imagenet',\n",
    "                    input_tensor=None , input_shape=(3, 224, 224)\n",
    "                                    )\n",
    "    print('Adding Average Pooling Layer and Softmax Output Layer ...')\n",
    "    output = ResNet50_notop.get_layer(index = -1).output  # Shape: (8, 8, 2048)    \n",
    "#    output = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(output)\n",
    "    output = Flatten(name='flatten')(output)\n",
    "    output = Dense(1, activation='relu', name='predictions')(output)\n",
    "\n",
    "    ResNet50_model = Model(ResNet50_notop.input, output)\n",
    "#    ResNet50_model.summary()\n",
    " #   exit(0)\n",
    "    optimizer = SGD(lr = learning_rate, momentum = 0.9, decay = 0.0, nesterov = True)\n",
    "    ResNet50_model.compile(loss='mae', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return ResNet50_model\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################ Main Routine ############################################\n",
    "def run_cross_validation_create_models(nfolds=3):\n",
    "    # input image dimensions\n",
    "    batch_size = 16 #16\n",
    "    nb_epoch = 2 #30\n",
    "    random_state = 51\n",
    "    models = [] \n",
    "    train_data, train_target, train_id = read_and_normalize_train_data()\n",
    "#    print train_target\n",
    "\n",
    "    y_for_folds=train_target.copy()\n",
    "#    train_target = np_utils.to_categorical(train_target)\n",
    "#    print train_target\n",
    "    \n",
    "    yfull_train = dict()\n",
    "    kf = KFold(len(train_id), n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "#   # kf = StratifiedKFold(y_for_folds, n_folds=nfolds, shuffle=True, random_state=random_state)\n",
    "    num_fold = 0\n",
    "    sum_score = 0\n",
    "    \n",
    "    \n",
    "\n",
    "\t\t\t\t\n",
    "    for train_index, test_index in kf:\n",
    "\t\t\t\t\t\n",
    "#        print len(train_data[train_index]), len((train_target[train_index]))\n",
    "        model = create_model_resnet()\n",
    "        X_train = train_data[train_index]\n",
    "        Y_train = train_target[train_index]\n",
    "        X_valid = train_data[test_index]\n",
    "        Y_valid = train_target[test_index]\n",
    "\n",
    "        num_fold += 1\n",
    "        \n",
    "\n",
    "        print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "        print('Split train: ', len(X_train), len(Y_train))\n",
    "        print('Split valid: ', len(X_valid), len(Y_valid))\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "#            best_model\n",
    "        ]\n",
    "        model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              shuffle=True, verbose=1, validation_data=(X_valid, Y_valid),\n",
    "              callbacks=callbacks)\n",
    "        \n",
    "        predictions_valid = model.predict(X_valid.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "        score = mean_absolute_error(Y_valid, predictions_valid)\n",
    "        print('Score log_loss: ', score)\n",
    "        sum_score += score*len(test_index)\n",
    "\n",
    "        # Store valid predictions\n",
    "        for i in range(len(test_index)):\n",
    "            yfull_train[test_index[i]] = predictions_valid[i]\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "    score = sum_score/len(train_data)\n",
    "    print(\"Total average loss score: \", score)\n",
    "\n",
    "    info_string = 'loss_' + str(score) + '_folds_' + str(nfolds) +'_ep_' + str(nb_epoch)\n",
    "    return info_string, models\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Keras version: {}'.format(keras_version))\n",
    "    num_folds = 2\n",
    "    path =r'./output_dir' \n",
    "    allFiles = glob.glob(path + \"/*.csv\")\n",
    "    allFilesimg = glob.glob(path + \"/*.png\")\n",
    "    info_string, models = run_cross_validation_create_models(num_folds)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
